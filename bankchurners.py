# -*- coding: utf-8 -*-
"""BankChurners.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mD5OTmpQ4mvSN4FsEVCrP4R9D-sDfsXu

# Import library
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from plotly.subplots import make_subplots
import plotly.figure_factory as ff

"""# Exploring the data"""

data = pd.read_csv("BankChurners.csv")

data.head(10)

"""### Data size"""

data.shape

"""### Check data types"""

data.dtypes

"""### Check null"""

display(data.isnull().sum())

"""### Count values"""

data.nunique()

"""### Drop unimportant columns

Xóa 2 cột cuối
"""

data.drop(['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1'], inplace = True, axis = 1)
data.drop(['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2'], inplace = True, axis = 1)

"""Xóa cột ID (không có ý nghĩa)"""

data.drop(['CLIENTNUM'], inplace = True, axis = 1)

"""Xóa những cột chỉ có một giá trị (không cần thiết trong trường hợp này)"""

for column in data.columns:
    if data[column].nunique() == 1:
        data.drop(column, inplace = True, axis = 1)

"""### Replace data

Thay thế một số dữ liệu dạng object
"""

data.dtypes

data['Attrition_Flag'] = data['Attrition_Flag'].replace('Existing Customer', 0)
data['Attrition_Flag'] = data['Attrition_Flag'].replace('Attrited Customer', 1)

"""Đối với các dữ liệu object không có tính cao thấp (giới tính, tình trạng hôn nhân), ta sử dụng phương pháp one hot encode để xử lý"""

one_hot_Gender = pd.get_dummies(data['Gender'])
one_hot_Marital_Status = pd.get_dummies(data['Marital_Status'])
one_hot_Education_Level = pd.get_dummies(data['Education_Level'])
one_hot_Income_Category = pd.get_dummies(data['Income_Category'])
one_hot_Card_Category = pd.get_dummies(data['Card_Category'])

data = data.join(pd.get_dummies(data['Education_Level'], prefix='Education_Level'))
data = data.join(pd.get_dummies(data['Income_Category'], prefix='Income_Category'))
data = data.join(pd.get_dummies(data['Gender'], prefix='Gender'))
data = data.join(pd.get_dummies(data['Marital_Status'], prefix='Marital_Status'))
data = data.join(pd.get_dummies(data['Card_Category'], prefix='Card_Category'))

data = data.drop('Gender',axis = 1)
data = data.drop('Marital_Status',axis = 1)
data = data.drop('Card_Category',axis = 1)
data = data.drop('Income_Category',axis = 1)
data = data.drop('Education_Level',axis = 1)

data.dtypes

data.describe(percentiles = [.1, .25, .5, .75, .97, .999])

"""# Visualize the data"""

for column in data.columns:
    if data[column].dtypes != object:
        fig = px.histogram(data, x=column, nbins=100,  color_discrete_sequence=['deepskyblue'],width=800, height=600)
        fig.show()

fig = ff.create_distplot([data['Customer_Age']], group_labels = ['Customer_Age'], colors = ['turquoise'], curve_type='normal')
fig.show()

P = [np.mean(data[data.Card_Category_Blue == 1].Attrition_Flag), np.mean(data[data.Card_Category_Silver == 1].Attrition_Flag), 
     np.mean(data[data.Card_Category_Gold == 1].Attrition_Flag), np.mean(data[data.Card_Category_Platinum == 1].Attrition_Flag)]
fig = px.bar(x = ['Blue', 'Silver', 'Gold', 'Platinum'], y = P, color_discrete_sequence= ['teal'], labels=dict(x="Categories", y="Ratio"), width=800, height=600)
fig.show()

P = [np.mean(data[data.Education_Level_Unknown == 1].Attrition_Flag), np.mean(data[data.Education_Level_Uneducated == 1].Attrition_Flag), 
     np.mean(data[data['Education_Level_High School'] == 1].Attrition_Flag), np.mean(data[data.Education_Level_College == 1].Attrition_Flag),
     np.mean(data[data.Education_Level_Graduate == 1].Attrition_Flag), np.mean(data[data['Education_Level_Post-Graduate'] == 1].Attrition_Flag),
     np.mean(data[data.Education_Level_Doctorate == 1].Attrition_Flag)]
fig = px.bar(x = ['Unknown', 'Uneducated', 'High School', 'College', 'Graduate', 'Post-Graduate', 'Doctorate'], y = P, color_discrete_sequence= ['teal'], labels=dict(x="Education_Level", y="Ratio"), width=800, height=600)
fig.show()

P = [np.mean(data[data.Marital_Status_Unknown == 1].Attrition_Flag), np.mean(data[data.Marital_Status_Single == 1].Attrition_Flag), 
     np.mean(data[data.Marital_Status_Married == 1].Attrition_Flag), np.mean(data[data.Marital_Status_Divorced == 1].Attrition_Flag)]
fig = px.bar(x = ['Unknown', 'Single', 'Married', 'Divorced'], y = P, color_discrete_sequence= ['teal'], labels=dict(x="Marital Status", y="Ratio"), width=800, height=600)
fig.show()

P = [np.mean(data[data.Gender_M == 1].Attrition_Flag), np.mean(data[data.Gender_F == 1].Attrition_Flag)]
fig = px.bar(x = ['Male', 'Female'], y = P, color_discrete_sequence= ['teal'], labels=dict(x="Gender", y="Ratio"), width=800, height=600)
fig.show()

fig = ff.create_distplot([data['Total_Trans_Ct']], group_labels = ['Total_Trans_Ct'], colors = ['turquoise'], curve_type='normal')
fig.show()

data.describe(percentiles = [.1, .25, .5, .75, .97, .999])

def normalize(a):
  return (a - a.min()) / (a.max() - a.min())

for column in data.columns:
    if data[column].max() > 1:
        data[column] = normalize(data[column])
data

plt.figure(figsize=(20,16))
correlations = data.corr()
sns.heatmap(round(correlations,2), cmap='GnBu', annot=True, 
            annot_kws={"size": 8}, vmin=-1, vmax=1);

data.columns

data = data.rename(columns={'Education_Level_High School': 'Education_Level_High_School',
                            'Education_Level_Post-Graduate': 'Education_Level_Post_Graduate',
                            'Income_Category_$120K +': 'Income_Category_120K',
                            'Income_Category_$40K - $60K': 'Income_Category_40K_60K',
                            'Income_Category_$60K - $80K': 'Income_Category_60K_80K',
                            'Income_Category_$80K - $120K': 'Income_Category_80K_120K',
                            'Income_Category_Less than $40K': 'Income_Category_Less_than_40K'})

import statsmodels.api as sm
from statsmodels.formula.api import ols
iris_lm=ols('Attrition_Flag ~  Customer_Age + Dependent_count + Education_Level_College + Education_Level_Doctorate + Education_Level_Graduate + Education_Level_High_School + Education_Level_Post_Graduate + Education_Level_Uneducated + Education_Level_Unknown + Income_Category_120K + Income_Category_40K_60K + Income_Category_60K_80K + Income_Category_80K_120K + Income_Category_Less_than_40K + Income_Category_Unknown + Card_Category_Blue + Card_Category_Silver + Card_Category_Gold + Card_Category_Platinum + Months_on_book + Total_Relationship_Count + Months_Inactive_12_mon + Contacts_Count_12_mon + Credit_Limit + Total_Revolving_Bal + Avg_Open_To_Buy + Total_Amt_Chng_Q4_Q1 + Total_Trans_Amt + Total_Trans_Ct + Total_Ct_Chng_Q4_Q1 + Avg_Utilization_Ratio + Gender_F + Gender_M + Marital_Status_Divorced + Marital_Status_Married + Marital_Status_Single + Marital_Status_Unknown', data=data).fit() #Specify C for Categorical
sm.stats.anova_lm(iris_lm, typ=2)

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
LOR = LogisticRegression(solver='liblinear', random_state=25)
y = np.array(data['Attrition_Flag'])
all_Data = data.drop(columns=['Attrition_Flag', 'Customer_Age', 'Card_Category_Blue', 'Months_on_book', 'Avg_Open_To_Buy', 'Avg_Utilization_Ratio'])

X = all_Data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .1, random_state=25)
LOR.fit(X_train, y_train)
LOR.score(X_test, y_test)

from sklearn.metrics import confusion_matrix
y_pred = LOR.predict(X_test)
confusion_matrix = confusion_matrix(y_test, y_pred)
confusion_matrix

from sklearn.model_selection import cross_val_score
print(cross_val_score(LOR, X, y, cv=10, scoring='accuracy').mean())

from sklearn.metrics import plot_roc_curve
LOR_disp = plot_roc_curve(LOR, X_test, y_test)
plt.show()

from sklearn.tree import DecisionTreeClassifier
DT = DecisionTreeClassifier()
DT.fit(X_train, y_train)
DT.score(X_test, y_test)

# print("Depth: ", DT.get_depth())
# print("Leaves: ", DT.get_n_leaves())

# from sklearn.metrics import confusion_matrix
# y_pred = DT.predict(X_test)
# cm = confusion_matrix(y_test, y_pred)
# cm

# from sklearn.model_selection import cross_val_score
# print(cross_val_score(DT, X, y, cv=10, scoring='accuracy').mean())

# from sklearn.metrics import plot_roc_curve
# DT_disp = plot_roc_curve(DT, X_test, y_test)
# plt.show()

from sklearn.metrics import confusion_matrix
y_pred = DT.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
cm

print("Depth: ", DT.get_depth())
print("Leaves: ", DT.get_n_leaves())

from sklearn.model_selection import cross_val_score
print(cross_val_score(DT, X, y, cv=10, scoring='accuracy').mean())